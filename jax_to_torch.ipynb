{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fcbe4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque, defaultdict\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "\n",
    "I_INF = 2**31 - 1  # large int sentinel (like jnp.int64 max)\n",
    "\n",
    "def fetch_first(mask: torch.Tensor) -> int:\n",
    "    \"\"\"Return the first index where mask is True, else I_INF.\"\"\"\n",
    "    idx = torch.nonzero(mask, as_tuple=True)[0]\n",
    "    return idx[0].item() if idx.numel() > 0 else I_INF\n",
    "\n",
    "def unflatten_conns(nodes: torch.Tensor, conns: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Transform the (C, CL) connections to (N, N), containing the index of each connection.\n",
    "    nodes: (N, node_attrs)\n",
    "    conns: (C, conn_attrs) where [:,0]=input_key, [:,1]=output_key\n",
    "    \"\"\"\n",
    "    N = nodes.shape[0]\n",
    "    C = conns.shape[0]\n",
    "    \n",
    "    node_keys = nodes[:, 0]\n",
    "    i_keys, o_keys = conns[:, 0], conns[:, 1]\n",
    "    \n",
    "    def key_to_index(key, keys):\n",
    "        return fetch_first(keys == key)\n",
    "    \n",
    "    i_idxs = torch.tensor([key_to_index(k.item(), node_keys) for k in i_keys], dtype=torch.int64)\n",
    "    o_idxs = torch.tensor([key_to_index(k.item(), node_keys) for k in o_keys], dtype=torch.int64)\n",
    "    \n",
    "    unflatten = torch.full((N, N), I_INF, dtype=torch.int64)\n",
    "    for idx, (i, o) in enumerate(zip(i_idxs, o_idxs)):\n",
    "        unflatten[i, o] = idx\n",
    "        \n",
    "    return unflatten\n",
    "\n",
    "def topological_sort(nodes: torch.Tensor, conns: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    A PyTorch version of topological_sort.\n",
    "    nodes: (N, node_attrs)\n",
    "    conns: (N, N) unflattened connection indices (not weights, just index presence)\n",
    "    \"\"\"\n",
    "    N = nodes.shape[0]\n",
    "    \n",
    "    # in_degree: count of incoming connections per node\n",
    "    valid_nodes = ~torch.isnan(nodes[:, 0])  # nodes with a key\n",
    "    in_degree = torch.where(valid_nodes, (conns != I_INF).sum(dim=0).float(), torch.nan)\n",
    "    \n",
    "    res = torch.full((N,), I_INF, dtype=torch.int64)\n",
    "    idx = 0\n",
    "    \n",
    "    while True:\n",
    "        zero_in = torch.nonzero(in_degree == 0.0, as_tuple=True)[0]\n",
    "        if zero_in.numel() == 0:\n",
    "            break\n",
    "        \n",
    "        i = zero_in[0].item()\n",
    "        res[idx] = i\n",
    "        idx += 1\n",
    "        in_degree[i] = -1  # mark visited\n",
    "        \n",
    "        children = conns[i, :] != I_INF\n",
    "        in_degree = torch.where(children, in_degree - 1, in_degree)\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, id_, input_=False, output=False, bias=0.0, initial_val=1.0):\n",
    "        self.id = id_\n",
    "        self.is_input = input_\n",
    "        self.is_output = output\n",
    "\n",
    "        self.bias = torch.tensor([bias], dtype=torch.float64)\n",
    "        self.initial_val = torch.tensor([initial_val], dtype=torch.float64)  # new attribute\n",
    "        self.val = None\n",
    "        \n",
    "        self.num_incoming_connections = 0 \n",
    "        self.received = None\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class ConnectionGene:\n",
    "    def __init__(self, in_node, out_node, innov_num, weight):\n",
    "        self.in_node = in_node # Nodes not node id\n",
    "        self.out_node = out_node\n",
    "        \n",
    "        self.innov_num = innov_num\n",
    "        \n",
    "        self.weight = weight # Weights are tensors\n",
    "        self.enable = True # If node is disabled, it CAN be reenabled\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class NN(nn.Module):\n",
    "\n",
    "    # For assigning node ids to new nodes\n",
    "    next_node_id = 0\n",
    "    \n",
    "    # key: (in, out) \n",
    "    # value: resulting node\n",
    "    resulting_node_map = {}\n",
    "\n",
    "    # key: (in, out) \n",
    "    # value: the innov_num \n",
    "    innov_num_map = {}\n",
    "    next_innov_num = 0\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, cloned=False):\n",
    "        super(NN, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.nodes = [] # Nodes objects in this specific NN\n",
    "        \n",
    "        self.connections_by_id = {} # Connections objects in this specific NN | in node id is key for forward lookup\n",
    "        self.connections = [] # All connections for mutating\n",
    "        \n",
    "        # Cloned models should not be inited!\n",
    "        if cloned:\n",
    "            return\n",
    "        else:\n",
    "            # When init a new model, the node nums and innov should be the same as any other new initialized model\n",
    "            # This branch is for initial population models\n",
    "            # Initalize a fully connected NN with no hidden layers\n",
    "            for i in range(input_dim):\n",
    "                if i >= NN.next_node_id:\n",
    "                    NN.next_node_id += 1\n",
    "                self.nodes.append(Node(i, True))\n",
    "    \n",
    "            for i in range(output_dim):\n",
    "                node_index = i + input_dim\n",
    "                if node_index >= NN.next_node_id:\n",
    "                    NN.next_node_id += 1\n",
    "                self.nodes.append(Node(node_index, False, True))\n",
    "\n",
    "                for in_id in range(input_dim):\n",
    "                    in_out_tuple = (in_id, node_index)\n",
    "                    \n",
    "                    if in_out_tuple not in NN.resulting_node_map:\n",
    "                        NN.resulting_node_map.update({in_out_tuple: None}) # No resulting node until it is split for the first time\n",
    "                        NN.innov_num_map.update({in_out_tuple: NN.next_innov_num}) # No resulting node until it is split for the first time\n",
    "                        NN.next_innov_num += 1\n",
    "                        \n",
    "                    innov_num = NN.innov_num_map[in_out_tuple]\n",
    "\n",
    "                    conn = ConnectionGene(self.nodes[in_id], self.nodes[node_index], innov_num, torch.randn(1))\n",
    "                    \n",
    "                    if in_id not in self.connections_by_id:\n",
    "                        self.connections_by_id[in_id] = [conn]\n",
    "                    else:\n",
    "                        self.connections_by_id[in_id].append(conn)\n",
    "\n",
    "                    self.connections.append(conn)\n",
    "                    \n",
    "                    self.nodes[node_index].num_incoming_connections += 1 # Each output starts off fully connected to input\n",
    "                            \n",
    "    def clone(self):\n",
    "        # Create a new NN instance with same input/output dims\n",
    "        new_nn = NN(self.input_dim, self.output_dim, cloned=True)\n",
    "    \n",
    "        # Deep copy nodes\n",
    "        new_nn.nodes = []\n",
    "        id_to_node = {}\n",
    "        for node in self.nodes:\n",
    "            new_node = Node(node.id, node.is_input, node.is_output)\n",
    "            new_node.num_incoming_connections = node.num_incoming_connections\n",
    "            new_nn.nodes.append(new_node)\n",
    "            id_to_node[node.id] = new_node\n",
    "    \n",
    "        # Deep copy connections\n",
    "        new_nn.connections = []\n",
    "\n",
    "        new_nn.connections_by_id = {}\n",
    "\n",
    "        for conn_list in self.connections_by_id.values():  # each value is a list of connections\n",
    "            for conn in conn_list:\n",
    "                in_node = id_to_node[conn.in_node.id]\n",
    "                out_node = id_to_node[conn.out_node.id]\n",
    "        \n",
    "                new_conn = ConnectionGene(\n",
    "                    in_node, out_node, conn.innov_num, conn.weight.clone().detach()\n",
    "                )\n",
    "                new_conn.enable = conn.enable\n",
    "\n",
    "                new_nn.connections.append(new_conn)\n",
    "\n",
    "                if in_node.id not in new_nn.connections_by_id:\n",
    "                    new_nn.connections_by_id[in_node.id] = [new_conn]\n",
    "                else:\n",
    "                    new_nn.connections_by_id[in_node.id].append(new_conn)\n",
    "        \n",
    "        return new_nn\n",
    "\n",
    "    import torch\n",
    "    from collections import deque\n",
    "    import torch.nn.functional as F\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Flatten square images\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        if x.shape[1] != self.input_dim:\n",
    "            raise ValueError(\"Input dim is not correct\")\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        device = x.device\n",
    "\n",
    "        # Reset node states\n",
    "        for node in self.nodes:\n",
    "            node.val = torch.zeros(batch_size, device=device)\n",
    "\n",
    "        # Set input values\n",
    "        for idx in range(self.input_dim):\n",
    "            self.nodes[idx].val = x[:, idx]\n",
    "\n",
    "        # Build tensors for nodes and connections\n",
    "        nodes_tensor = torch.tensor([[node.id] for node in self.nodes], dtype=torch.float64, device=device)\n",
    "        conns_tensor = torch.tensor(\n",
    "            [[conn.in_node.id, conn.out_node.id] for conn in self.connections if conn.enable],\n",
    "            dtype=torch.float64,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Create adjacency matrix and get topological order\n",
    "        unflat = unflatten_conns(nodes_tensor, conns_tensor)        # (N, N)\n",
    "        topo_order = topological_sort(nodes_tensor, unflat)         # (N,)\n",
    "\n",
    "        # Traverse nodes in topological order\n",
    "        for idx in topo_order:\n",
    "            if idx == I_INF:\n",
    "                break  # unused slots\n",
    "\n",
    "            curr_node = self.nodes[int(idx.item())]\n",
    "\n",
    "            # Skip input nodes (already set)\n",
    "            if curr_node.is_input:\n",
    "                continue\n",
    "\n",
    "            # Aggregate inputs\n",
    "            total_input = torch.zeros(batch_size, device=device)\n",
    "            for conn in self.connections:\n",
    "                if conn.enable and conn.out_node.id == curr_node.id:\n",
    "                    total_input += conn.in_node.val * conn.weight\n",
    "\n",
    "            # Now multiply by initial_val and then add bias:\n",
    "            total_input = total_input * curr_node.initial_val + curr_node.bias\n",
    "\n",
    "            # Activation:\n",
    "            if curr_node.is_output:\n",
    "                curr_node.val = F.relu(total_input)\n",
    "            else:\n",
    "                curr_node.val = torch.sigmoid(total_input)\n",
    "\n",
    "\n",
    "        # Collect logits from output nodes\n",
    "        output_vals = [node.val for node in self.nodes if node.is_output]\n",
    "        logits = torch.stack(output_vals, dim=1)  # shape: (batch_size, num_outputs)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def creates_cycle(self, source, target):\n",
    "        \"\"\"Returns True if adding an edge from `source` to `target` would create a cycle.\"\"\"\n",
    "        visited = set()\n",
    "    \n",
    "        def dfs(node):\n",
    "            if node.id in visited:\n",
    "                return False\n",
    "            if node == source:\n",
    "                return True  # Found a path back to source — would create cycle\n",
    "            visited.add(node.id)\n",
    "            for conn in self.connections:\n",
    "                if conn.enable and conn.in_node == node:\n",
    "                    if dfs(conn.out_node):\n",
    "                        return True\n",
    "            return False\n",
    "    \n",
    "    def to(self, device):\n",
    "        for node in self.nodes:\n",
    "            if node.val is not None:\n",
    "                node.val = node.val.to(device)\n",
    "            if node.received is not None:\n",
    "                node.received = node.received.to(device)\n",
    "        for conn in self.connections:\n",
    "            conn.weight = conn.weight.to(device)\n",
    "        return self\n",
    "    \n",
    "    @classmethod\n",
    "    def from_numpy(cls, nodes_np: np.ndarray, conns_np: np.ndarray, input_dim: int, output_dim: int):\n",
    "        new_nn = cls(input_dim, output_dim, cloned=True)\n",
    "        \n",
    "        new_nn.nodes = []\n",
    "        new_nn.connections = []\n",
    "        new_nn.connections_by_id = {}\n",
    "        \n",
    "        id_to_node = {}\n",
    "        \n",
    "        for row in nodes_np:\n",
    "            node_id = int(row[0])\n",
    "            bias = float(row[1])\n",
    "            initial_val = float(row[2])  # <-- get initial_val here\n",
    "            is_input = node_id < input_dim\n",
    "            is_output = input_dim <= node_id < input_dim + output_dim\n",
    "            \n",
    "            node = Node(node_id, is_input, is_output, bias=bias, initial_val=initial_val)\n",
    "            new_nn.nodes.append(node)\n",
    "            id_to_node[node_id] = node\n",
    "        \n",
    "        \n",
    "        # Add connections (same as before)\n",
    "        for row in conns_np:\n",
    "            in_id, out_id, weight = int(row[0]), int(row[1]), torch.tensor([row[2]], dtype=torch.float64)\n",
    "            \n",
    "            in_node = id_to_node[in_id]\n",
    "            out_node = id_to_node[out_id]\n",
    "            \n",
    "            in_out_tuple = (in_id, out_id)\n",
    "            if in_out_tuple not in NN.innov_num_map:\n",
    "                NN.innov_num_map[in_out_tuple] = NN.next_innov_num\n",
    "                NN.resulting_node_map[in_out_tuple] = None\n",
    "                NN.next_innov_num += 1\n",
    "            \n",
    "            innov_num = NN.innov_num_map[in_out_tuple]\n",
    "            conn = ConnectionGene(in_node, out_node, innov_num, weight)\n",
    "            \n",
    "            if in_id not in new_nn.connections_by_id:\n",
    "                new_nn.connections_by_id[in_id] = [conn]\n",
    "            else:\n",
    "                new_nn.connections_by_id[in_id].append(conn)\n",
    "            \n",
    "            new_nn.connections.append(conn)\n",
    "            out_node.num_incoming_connections += 1\n",
    "        \n",
    "        NN.next_node_id = max(NN.next_node_id, max(id_to_node.keys()) + 1)\n",
    "        \n",
    "        return new_nn\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_pickle(cls, filepath: str, input_dim: int, output_dim: int):\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        # If you saved arrays directly\n",
    "        if isinstance(data, tuple) and len(data) == 2:\n",
    "            nodes_np, conns_np = data\n",
    "        # If saved as dict\n",
    "        elif isinstance(data, dict):\n",
    "            nodes_np = data[\"nodes\"]\n",
    "            conns_np = data[\"conns\"]\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported pickle format\")\n",
    "\n",
    "        return cls.from_numpy(nodes_np, conns_np, input_dim, output_dim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def reset_NN_class_state():\n",
    "    NN.next_node_id = 0\n",
    "    NN.resulting_node_map = {}\n",
    "    NN.innov_num_map = {}\n",
    "    NN.next_innov_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb8d0093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00, -1.9828e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.0000e+00, -1.3459e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.0000e+00,  3.5875e-01,  0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 7.9300e+02, -2.4648e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.9411e+04, -8.0786e-01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.0350e+05,  1.3595e-02,  0.0000e+00, -1.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.set_default_dtype(torch.float64)\n",
    "# Load .npz file\n",
    "data = np.load(\"models/genomes/49.npz\")\n",
    "\n",
    "with open(\"models/4.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Access arrays by keys\n",
    "X_val = torch.tensor(data[\"nodes\"], dtype=torch.float64)\n",
    "Y_val = torch.tensor(data[\"conns\"], dtype=torch.float64)\n",
    "\n",
    "# Convert and remove NaNs\n",
    "nodes_clean = data[\"nodes\"][~np.isnan(data[\"nodes\"]).any(axis=1)]\n",
    "conns_clean = data[\"conns\"][~np.isnan(data[\"conns\"]).any(axis=1)]\n",
    "\n",
    "X_val = torch.tensor(nodes_clean, dtype=torch.float64)\n",
    "Y_val = torch.tensor(conns_clean, dtype=torch.float64)\n",
    "print(X_val)\n",
    "model = NN.from_numpy(X_val, Y_val, input_dim=784, output_dim=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "09f7821a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval\n",
    "def evaluate_model(model, batch_size=256):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.view(-1))  # Flatten 28x28 → 784\n",
    "    ])\n",
    "\n",
    "    test_dataset = datasets.MNIST(\n",
    "        root=\"./data\",\n",
    "        train=True,\n",
    "        transform=transform,\n",
    "        download=True\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    eps = 1e-8\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)                     # [batch, num_classes]\n",
    "            probs = F.softmax(outputs, dim=1)           # match JAX preds\n",
    "            Y_onehot = F.one_hot(labels, num_classes=10).float()\n",
    "\n",
    "            # Manual cross-entropy: -mean(sum(Y * log(preds)))\n",
    "            loss = -(Y_onehot * torch.log(probs + eps)).sum(dim=1).mean()\n",
    "\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            predicted_classes = torch.argmax(probs, dim=-1)\n",
    "            correct += (predicted_classes == labels).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = correct / total_samples\n",
    "\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7f484412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.4509, Accuracy: 0.0986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09863333333333334"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83922c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
